group_by(file) %>%
# To make sure they are in the right order
arrange(onset) %>%
mutate(next_sound = lead(phone)) %>%
mutate(previous_sound = lag(phone)) %>%
ungroup()
#the pedestrian way, which takes forever
# for(line in 1:nrow(alignments)){
#   if(line > 1){
#     if(alignments$file[line]==alignments$file[line-1]){
#       alignments$previous_sound[line] = as.character(alignments$phone[line-1])
#     }
#     else{alignments$previous_sound[line] = "_"}
#   }
#   else{alignments$previous_sound[line] = "_"}
#   if(line < length(alignments$file) & alignments$file[line]==alignments$file[line+1]){
#     alignments$next_sound[line] = as.character(alignments$phone[line+1])
#   }
#   else{alignments$next_sound[line] = "_"}
# }
alignments = as.data.frame(data)
alignments$previous_sound=ifelse(is.na(alignments$previous_sound), "_", alignments$previous_sound)
alignments$next_sound=ifelse(is.na(alignments$next_sound), "_", alignments$next_sound)
alignments$context = paste(alignments$previous_sound, alignments$next_sound, sep="-")
#Now we set different thresholds and create item files accordingly
threshold = 1
thresholded = subset(alignments, posterior>=threshold)
#for simplicity split into vowels and consonant files
vowels = c("aa", "ae", "ah", "ao", "aw", "ax", "ay", "eh", "er", "ey", "ih", "iy", "ow", "oy", "uh", "uw")
brent.vowels = droplevels(subset(thresholded, phone %in% vowels))
brent.cons = droplevels(subset(thresholded, !(phone %in% vowels)))
#Make the data structure fit the file format for easier write out later.
brent.vowels =  brent.vowels[c("file", "onset", "offset", "phone", "context", "talker")]
brent.cons =  brent.cons[c("file", "onset", "offset", "phone", "context", "talker")]
vowfile = paste("Brent_vowels_", as.character(threshold),".item", sep="")
consfile = paste("Brent_cons_", as.character(threshold),".item", sep="")
file.create(vowfile)
file.create(consfile)
write("#file onset offset #phone context talker", file = vowfile)
write("#file onset offset #phone context talker", file = consfile)
#Next we want to remove those elements where a context does not appear in all talkers per phone
talkers = levels(as.factor(thresholded$talker))
contexts = levels(as.factor(thresholded$context))
phones = levels(as.factor(brent.cons$phone))
phones
phones[-"SIL"]
phones[phones != "SIL"]
phones = levels(as.factor(brent.vowels$phone))
phones
alignments = read.csv("Supplementary/alignement.csv", header = FALSE)
segments_data = read.csv("Supplementary/segments.csv", header = FALSE)
names(alignments) <-  c("segment", "phone_onset", "phone_offset", "posterior", "phone", "word")
names(segments_data) <- c("segment", "file", "segmentonset", "segmentoffset")
alignments$talker = substring(alignments$segment, 1, 2)
alignments$phone = as.character(alignments$phone)
data = left_join(alignments, segments_data, by = "segment") %>%
mutate(onset = phone_onset+segmentonset) %>%
mutate(offset = phone_offset+segmentonset) %>%
#Many thanks to Page Piccinini (page.piccinini 'at' gmail) for this code snippet which greatly improved efficiency
# To make sure it's all within file
group_by(file) %>%
# To make sure they are in the right order
arrange(onset) %>%
mutate(next_sound = lead(phone)) %>%
mutate(previous_sound = lag(phone)) %>%
ungroup()
#the pedestrian way, which takes forever
# for(line in 1:nrow(alignments)){
#   if(line > 1){
#     if(alignments$file[line]==alignments$file[line-1]){
#       alignments$previous_sound[line] = as.character(alignments$phone[line-1])
#     }
#     else{alignments$previous_sound[line] = "_"}
#   }
#   else{alignments$previous_sound[line] = "_"}
#   if(line < length(alignments$file) & alignments$file[line]==alignments$file[line+1]){
#     alignments$next_sound[line] = as.character(alignments$phone[line+1])
#   }
#   else{alignments$next_sound[line] = "_"}
# }
alignments = as.data.frame(data)
alignments$previous_sound=ifelse(is.na(alignments$previous_sound), "_", alignments$previous_sound)
alignments$next_sound=ifelse(is.na(alignments$next_sound), "_", alignments$next_sound)
alignments$context = paste(alignments$previous_sound, alignments$next_sound, sep="-")
#Now we set different thresholds and create item files accordingly
threshold = 1
thresholded = subset(alignments, posterior>=threshold)
#for simplicity split into vowels and consonant files
vowels = c("aa", "ae", "ah", "ao", "aw", "ax", "ay", "eh", "er", "ey", "ih", "iy", "ow", "oy", "uh", "uw")
brent.vowels = droplevels(subset(thresholded, phone %in% vowels))
brent.cons = droplevels(subset(thresholded, !(phone %in% vowels)))
#Make the data structure fit the file format for easier write out later.
brent.vowels =  brent.vowels[c("file", "onset", "offset", "phone", "context", "talker")]
brent.cons =  brent.cons[c("file", "onset", "offset", "phone", "context", "talker")]
vowfile = paste("Brent_vowels_", as.character(threshold),".item", sep="")
consfile = paste("Brent_cons_", as.character(threshold),".item", sep="")
file.create(vowfile)
file.create(consfile)
write("#file onset offset #phone context talker", file = vowfile)
write("#file onset offset #phone context talker", file = consfile)
#Next we want to remove those elements where a context does not appear in all talkers per phone
talkers = levels(as.factor(thresholded$talker))
contexts = levels(as.factor(thresholded$context))
phones = levels(as.factor(brent.cons$phone))
#This is a very roundabout way and I am sure in dplyr there are better solutions.
for(phone in phones[phones != "SIL"]){
for(context in contexts){
subset = brent.cons[brent.cons$phone==phone & brent.cons$context==context, ]
if(length(unique(subset$talker))==length(talkers)){
write.table(subset, append = TRUE, sep = " ", col.names= FALSE, row.names = FALSE, quote = FALSE, file = consfile)
}
}
}
phones = levels(as.factor(brent.vowels$phone))
for(phone in phones){
for(context in contexts){
subset = brent.vowels[brent.vowels$phone==phone & brent.vowels$context==context, ]
if(length(unique(subset$talker))==length(talkers)){
write.table(subset, append = TRUE, sep = " ", col.names= FALSE, row.names = FALSE, quote = FALSE, file = vowfile)
}
}
}
# load libraries
library(plyr)
#The acoustic encoding is MEL, change here to to other encodings when available, eg to MFCC (all lowercase)
acoustic = "mel"
#Which distance measure is used?
distance = "avg"
#To be sure that there are no unnecessary comparisons between consonants and vowels, I separated the two. Also faster.
withinfile_vowels = paste("Data/Buckeye_withinSpeaker_vowel_", acoustic, "_", distance,".csv", sep="")
betweenfile_vowels = paste("Data/Buckeye_acrossSpeaker_vowel_", acoustic, "_", distance,".csv", sep="")
withinfile_cons = paste("Data/Brent_Clean_withinSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
betweenfile_cons = paste("Data/Brent_Clean_acrossSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
read.table(betweenfile_vowels,sep="\t",header=T)->rawdata_between_temp
read.table(betweenfile_cons,sep="\t",header=T)->rawdata_between
rawdata_between = rbind(rawdata_between, rawdata_between_temp)
read.table(withinfile_vowels,sep="\t",header=T)->rawdata_within_temp
read.table(withinfile_cons,sep="\t",header=T)->rawdata_within
rawdata_within = rbind(rawdata_within, rawdata_within_temp)
remove(rawdata_within_temp, rawdata_between_temp)
withinfile_vowels = paste("Data/Brent_Clean_withinSpeaker_vowels_", acoustic, "_", distance,".csv", sep="")
betweenfile_vowels = paste("Data/Brent_Clean_acrossSpeaker_vowels_", acoustic, "_", distance,".csv", sep="")
read.table(betweenfile_vowels,sep="\t",header=T)->rawdata_between_temp
read.table(betweenfile_cons,sep="\t",header=T)->rawdata_between
rawdata_between = rbind(rawdata_between, rawdata_between_temp)
read.table(withinfile_vowels,sep="\t",header=T)->rawdata_within_temp
read.table(withinfile_cons,sep="\t",header=T)->rawdata_within
rawdata_within = rbind(rawdata_within, rawdata_within_temp)
remove(rawdata_within_temp, rawdata_between_temp)
rawdata_between$contrasts <- as.factor(ifelse((as.character(rawdata_between$phone_1)<as.character(rawdata_between$phone_2)), paste(rawdata_between$phone_1, rawdata_between$phone_2, sep = "-"), paste(rawdata_between$phone_2, rawdata_between$phone_1, sep = "-")))
rawdata_between$speakerpairs <- as.factor(ifelse((as.character(rawdata_between$talker_1)<as.character(rawdata_between$talker_2)), paste(rawdata_between$talker_1, rawdata_between$talker_2, sep = "-"), paste(rawdata_between$talker_2, rawdata_between$talker_1, sep = "-")))
names(rawdata_between)[names(rawdata_between)=="by"] <- "context"
rawdata_within$contrasts <- as.factor(ifelse((as.character(rawdata_within$phone_1)<as.character(rawdata_within$phone_2)), paste(rawdata_within$phone_1, rawdata_within$phone_2, sep = "-"), paste(rawdata_within$phone_2, rawdata_within$phone_1, sep = "-")))
rawdata_within$speaker <- as.factor(gsub(")", "", (gsub("^.*?, ","", (gsub("^.*?, ","", as.character(rawdata_within$by)))))))
rawdata_within$context <- as.factor(gsub("[(), ]", "", (gsub("\\d","", as.character(rawdata_within$by)))))
rawdata_within <- subset(rawdata_within, select = -c(by))
remove("acoustic", "betweenfile_cons", "betweenfile_vowels", "distance", "withinfile_cons", "withinfile_vowels")
#For sampling later we need to add this column
rawdata_within$speakerpairs = paste(rawdata_within$speaker, rawdata_within$speaker, sep="-")
#Step 1, have one mean score per contrast-speaker(pair)
between_percontrastspeaker = rawdata_between %>%
group_by(speakerpairs, contrasts) %>%
summarise(mean_score_temp = mean(score)) %>%
ungroup()
within_contrast = rawdata_within%>%
group_by(contrasts) %>%
summarise(sum_n = sum(n)) %>%
ungroup()
within_percontrastspeaker = rawdata_within %>%
group_by(speakerpairs, contrasts) %>%
summarise(mean_score_temp = mean(score)) %>%
ungroup()
#Step 2: Have one number per speaker(pair)
between = between_percontrastspeaker %>%
group_by(speakerpairs) %>%
summarise(mean_score = mean(mean_score_temp)) %>%
ungroup()
within = within_percontrastspeaker %>%
group_by(speakerpairs) %>%
summarise(mean_score = mean(mean_score_temp)) %>%
ungroup()
#Step 3: Final score
between_score = mean(between$mean_score)
within_score = mean(within$mean_score)
#### Difference score ####
#→ do within minus between → (difference score)
difference_score = within_score-between_score
sampling_data = merge(between, within, all = TRUE)
n_loops = 10000
n_within = length(within$speakerpairs)
n_between = length(between$speakerpairs)
within_results = matrix(NA, nrow = n_loops, ncol = 1)
between_results = matrix(NA, nrow = n_loops, ncol = 1)
diff_results = matrix(NA, nrow = n_loops, ncol = 1)
set.seed(111)
for(loop in 1:n_loops){
within_sampling_rows = sample(nrow(sampling_data), n_within)
sample_within = sampling_data[within_sampling_rows, ]
sample_between = sampling_data[-within_sampling_rows, ]
#Step 3: Final score, directly record
between_results[loop] = mean(sample_between$mean_score)
within_results[loop] = mean(sample_within$mean_score)
#→ do within minus between → (difference score)
diff_results[loop] = mean(sample_within$mean_score) - mean(sample_between$mean_score)
}
hist(diff_results)
withinfile_cons = paste("Data/Brent_Clean_withinSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
betweenfile_cons = paste("Data/Brent_Clean_acrossSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
read.table(betweenfile_cons,sep="\t",header=T)->rawdata_between
read.table(withinfile_cons,sep="\t",header=T)->rawdata_within
rawdata_between$contrasts <- as.factor(ifelse((as.character(rawdata_between$phone_1)<as.character(rawdata_between$phone_2)), paste(rawdata_between$phone_1, rawdata_between$phone_2, sep = "-"), paste(rawdata_between$phone_2, rawdata_between$phone_1, sep = "-")))
rawdata_between$speakerpairs <- as.factor(ifelse((as.character(rawdata_between$talker_1)<as.character(rawdata_between$talker_2)), paste(rawdata_between$talker_1, rawdata_between$talker_2, sep = "-"), paste(rawdata_between$talker_2, rawdata_between$talker_1, sep = "-")))
names(rawdata_between)[names(rawdata_between)=="by"] <- "context"
rawdata_within$contrasts <- as.factor(ifelse((as.character(rawdata_within$phone_1)<as.character(rawdata_within$phone_2)), paste(rawdata_within$phone_1, rawdata_within$phone_2, sep = "-"), paste(rawdata_within$phone_2, rawdata_within$phone_1, sep = "-")))
rawdata_within$speaker <- as.factor(gsub(")", "", (gsub("^.*?, ","", (gsub("^.*?, ","", as.character(rawdata_within$by)))))))
rawdata_within$context <- as.factor(gsub("[(), ]", "", (gsub("\\d","", as.character(rawdata_within$by)))))
rawdata_within <- subset(rawdata_within, select = -c(by))
withinfile_cons = paste("../Brent/Data/Brent_withinSpeaker_cons_", acoustic, "_", distance,"_t.csv", sep="")
betweenfile_cons = paste("../Brent/Data/Brent_acrossSpeaker_cons_", acoustic, "_", distance,"_t.csv", sep="")
read.table(betweenfile_cons,sep="\t",header=T)->rawdata_between_old
read.table(withinfile_cons,sep="\t",header=T)->rawdata_within_old
rawdata_between_old$contrasts <- as.factor(ifelse((as.character(rawdata_between_old$sound_1)<as.character(rawdata_between_old$sound_2)), paste(rawdata_between_old$sound_1, rawdata_between_old$sound_2, sep = "-"), paste(rawdata_between_old$sound_2, rawdata_between_old$sound_1, sep = "-")))
rawdata_between_old$speakerpairs <- as.factor(ifelse((as.character(rawdata_between_old$child_1)<as.character(rawdata_between_old$child_2)), paste(rawdata_between_old$child_1, rawdata_between_old$child_2, sep = "-"), paste(rawdata_between_old$child_2, rawdata_between_old$child_1, sep = "-")))
rawdata_within_old$contrasts <- as.factor(ifelse((as.character(rawdata_within_old$sound_1)<as.character(rawdata_within_old$sound_2)), paste(rawdata_within_old$sound_1, rawdata_within_old$sound_2, sep = "-"), paste(rawdata_within_old$sound_2, rawdata_within_old$sound_1, sep = "-")))
rawdata_within_old$speaker <- as.factor(gsub(")", "", (gsub("^.*?, ","", (gsub("^.*?, ","", as.character(rawdata_within_old$by)))))))
rawdata_within_old$context <- as.factor(gsub("\\(| ", "", (gsub(".{5}$","", as.character(rawdata_within_old$by)))))
rawdata_between_old$context <-as.factor(gsub("\\(|\\)| ", "", as.character(rawdata_between_old$by)))
par(pty="s")
plot(c(.45,1.), c(.45, 1.), type="n",xlab="Within-Speaker ABX Score",ylab="Across-Speaker ABX Score",main = "ABX scores", xlim=c(0.45,.99),ylim=c(0.45,.99), frame.plot = FALSE)
axis(side = 1)
for (thiscontrast in levels(rawdata_within$contrasts)) {
between_score = rawdata_between$score[rawdata_between$contrasts == thiscontrast]
within_score = rawdata_within$score[rawdata_within$contrasts == thiscontrast]
points(mean(within_score), mean(between_score), pch = 1, cex =1)
}
for (thiscontrast in levels(rawdata_within_old$contrasts)) {
between_score = rawdata_between_old$score[rawdata_between_old$contrasts == thiscontrast]
within_score = rawdata_within_old$score[rawdata_within_old$contrasts == thiscontrast]
points(mean(within_score), mean(between_score), pch = 4, cex =.5, col = "blue")
}
lines(c(0.45,1.),c(0.45,1.),col="red",lty=3)
# load libraries
library(plyr)
#The acoustic encoding is MEL, change here to to other encodings when available, eg to MFCC (all lowercase)
acoustic = "mel"
#Which distance measure is used?
distance = "avg"
#To be sure that there are no unnecessary comparisons between consonants and vowels, I separated the two. Also faster.
withinfile_vowels = paste("Data/Brent_Clean_withinSpeaker_vowels_", acoustic, "_", distance,".csv", sep="")
betweenfile_vowels = paste("Data/Brent_Clean_acrossSpeaker_vowels_", acoustic, "_", distance,".csv", sep="")
withinfile_cons = paste("Data/Brent_Clean_withinSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
betweenfile_cons = paste("Data/Brent_Clean_acrossSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
read.table(betweenfile_vowels,sep="\t",header=T)->rawdata_between_temp
read.table(betweenfile_cons,sep="\t",header=T)->rawdata_between
rawdata_between = rbind(rawdata_between, rawdata_between_temp)
read.table(withinfile_vowels,sep="\t",header=T)->rawdata_within_temp
read.table(withinfile_cons,sep="\t",header=T)->rawdata_within
rawdata_within = rbind(rawdata_within, rawdata_within_temp)
remove(rawdata_within_temp, rawdata_between_temp)
rawdata_between$contrasts <- as.factor(ifelse((as.character(rawdata_between$phone_1)<as.character(rawdata_between$phone_2)), paste(rawdata_between$phone_1, rawdata_between$phone_2, sep = "-"), paste(rawdata_between$phone_2, rawdata_between$phone_1, sep = "-")))
rawdata_between$speakerpairs <- as.factor(ifelse((as.character(rawdata_between$talker_1)<as.character(rawdata_between$talker_2)), paste(rawdata_between$talker_1, rawdata_between$talker_2, sep = "-"), paste(rawdata_between$talker_2, rawdata_between$talker_1, sep = "-")))
names(rawdata_between)[names(rawdata_between)=="by"] <- "context"
rawdata_within$contrasts <- as.factor(ifelse((as.character(rawdata_within$phone_1)<as.character(rawdata_within$phone_2)), paste(rawdata_within$phone_1, rawdata_within$phone_2, sep = "-"), paste(rawdata_within$phone_2, rawdata_within$phone_1, sep = "-")))
rawdata_within$speaker <- as.factor(gsub(")", "", (gsub("^.*?, ","", (gsub("^.*?, ","", as.character(rawdata_within$by)))))))
rawdata_within$context <- as.factor(gsub("[(), ]", "", (gsub("\\d","", as.character(rawdata_within$by)))))
rawdata_within <- subset(rawdata_within, select = -c(by))
remove("acoustic", "betweenfile_cons", "betweenfile_vowels", "distance", "withinfile_cons", "withinfile_vowels")
sampling_data = merge(between, within, all = TRUE)
n_loops = 10000
n_within = length(within$speakerpairs)
n_between = length(between$speakerpairs)
within_results = matrix(NA, nrow = n_loops, ncol = 1)
between_results = matrix(NA, nrow = n_loops, ncol = 1)
diff_results = matrix(NA, nrow = n_loops, ncol = 1)
set.seed(111)
for(loop in 1:n_loops){
within_sampling_rows = sample(nrow(sampling_data), n_within)
sample_within = sampling_data[within_sampling_rows, ]
sample_between = sampling_data[-within_sampling_rows, ]
#Step 3: Final score, directly record
between_results[loop] = mean(sample_between$mean_score)
within_results[loop] = mean(sample_within$mean_score)
#→ do within minus between → (difference score)
diff_results[loop] = mean(sample_within$mean_score) - mean(sample_between$mean_score)
}
#For sampling later we need to add this column
rawdata_within$speakerpairs = paste(rawdata_within$speaker, rawdata_within$speaker, sep="-")
#pipeline, as agreed on by Bergmann, Cristia, Dupoux in June 2016
#Cf https://docs.google.com/document/d/1x0lpC0sgho8k9h0gE3gi0VwWgcZ2RyTd1uM0nRBhjXE/edit
#### Effect per condition (within and across speaker) ####
#Average over contexts → average over contrasts  → (one number per speaker-speaker) →
# average all s-s in within and, separately, all s-s in between → (average effect)
#Step 1, have one mean score per contrast-speaker(pair)
between_percontrastspeaker = rawdata_between %>%
group_by(speakerpairs, contrasts) %>%
summarise(mean_score_temp = mean(score)) %>%
ungroup()
within_contrast = rawdata_within%>%
group_by(contrasts) %>%
summarise(sum_n = sum(n)) %>%
ungroup()
within_percontrastspeaker = rawdata_within %>%
group_by(speakerpairs, contrasts) %>%
summarise(mean_score_temp = mean(score)) %>%
ungroup()
#Step 2: Have one number per speaker(pair)
between = between_percontrastspeaker %>%
group_by(speakerpairs) %>%
summarise(mean_score = mean(mean_score_temp)) %>%
ungroup()
within = within_percontrastspeaker %>%
group_by(speakerpairs) %>%
summarise(mean_score = mean(mean_score_temp)) %>%
ungroup()
#Step 3: Final score
between_score = mean(between$mean_score)
within_score = mean(within$mean_score)
#### Difference score ####
#→ do within minus between → (difference score)
difference_score = within_score-between_score
#### Create a null distribution: Random Sampling per speakerpair (re-assigininh within and across speaker) ####
#Then take matrix and shuffle the within & between labels 10,000 →
#average all s-s in within and, separately, all s-s in between → (average effect) → do within minus between → (difference score)
sampling_data = merge(between, within, all = TRUE)
n_loops = 10000
n_within = length(within$speakerpairs)
n_between = length(between$speakerpairs)
within_results = matrix(NA, nrow = n_loops, ncol = 1)
between_results = matrix(NA, nrow = n_loops, ncol = 1)
diff_results = matrix(NA, nrow = n_loops, ncol = 1)
set.seed(111)
for(loop in 1:n_loops){
within_sampling_rows = sample(nrow(sampling_data), n_within)
sample_within = sampling_data[within_sampling_rows, ]
sample_between = sampling_data[-within_sampling_rows, ]
#Step 3: Final score, directly record
between_results[loop] = mean(sample_between$mean_score)
within_results[loop] = mean(sample_within$mean_score)
#→ do within minus between → (difference score)
diff_results[loop] = mean(sample_within$mean_score) - mean(sample_between$mean_score)
}
#### Goal: Get CI for each contrast ####
# 1. Average over contexts → 2. average over s-s-w and, separately, s-s-b per contrast → 3. do the difference per contrast → 4. average effect per contrast
#shuffle s-s-w and s-s-b labels after step 1 and redo 2-4 10k times
#We already averaged over contexts and can just use: between_percontrastspeaker, within_percontrastspeaker
par(pty="s")
plot(c(.45,1.), c(.45, 1.), type="n",xlab="Within-Speaker ABX Score",ylab="Across-Speaker ABX Score",main = "ABX scores", xlim=c(0.45,.99),ylim=c(0.45,.99), frame.plot = FALSE)
axis(side = 1)
for (thiscontrast in levels(rawdata_within$contrasts)) {
between_score = rawdata_between$score[rawdata_between$contrasts == thiscontrast]
within_score = rawdata_within$score[rawdata_within$contrasts == thiscontrast]
points(mean(within_score), mean(between_score), pch = 1, cex =1)
}
lines(c(0.45,1.),c(0.45,1.),col="red",lty=3)
# load libraries
library(plyr)
#The acoustic encoding is MEL, change here to to other encodings when available, eg to MFCC (all lowercase)
acoustic = "mel"
#Which distance measure is used?
distance = "avg"
#To be sure that there are no unnecessary comparisons between consonants and vowels, I separated the two. Also faster.
withinfile_vowels = paste("Data/Brent_Clean_withinSpeaker_vowels_", acoustic, "_", distance,".csv", sep="")
betweenfile_vowels = paste("Data/Brent_Clean_acrossSpeaker_vowels_", acoustic, "_", distance,".csv", sep="")
withinfile_cons = paste("Data/Brent_Clean_withinSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
betweenfile_cons = paste("Data/Brent_Clean_acrossSpeaker_cons_", acoustic, "_", distance,".csv", sep="")
read.table(betweenfile_vowels,sep="\t",header=T)->rawdata_between_temp
read.table(betweenfile_cons,sep="\t",header=T)->rawdata_between
rawdata_between = rbind(rawdata_between, rawdata_between_temp)
read.table(withinfile_vowels,sep="\t",header=T)->rawdata_within_temp
read.table(withinfile_cons,sep="\t",header=T)->rawdata_within
rawdata_within = rbind(rawdata_within, rawdata_within_temp)
remove(rawdata_within_temp, rawdata_between_temp)
rawdata_between$contrasts <- as.factor(ifelse((as.character(rawdata_between$phone_1)<as.character(rawdata_between$phone_2)), paste(rawdata_between$phone_1, rawdata_between$phone_2, sep = "-"), paste(rawdata_between$phone_2, rawdata_between$phone_1, sep = "-")))
rawdata_between$speakerpairs <- as.factor(ifelse((as.character(rawdata_between$talker_1)<as.character(rawdata_between$talker_2)), paste(rawdata_between$talker_1, rawdata_between$talker_2, sep = "-"), paste(rawdata_between$talker_2, rawdata_between$talker_1, sep = "-")))
names(rawdata_between)[names(rawdata_between)=="by"] <- "context"
rawdata_within$contrasts <- as.factor(ifelse((as.character(rawdata_within$phone_1)<as.character(rawdata_within$phone_2)), paste(rawdata_within$phone_1, rawdata_within$phone_2, sep = "-"), paste(rawdata_within$phone_2, rawdata_within$phone_1, sep = "-")))
rawdata_within$speaker <- as.factor(gsub(")", "", (gsub("^.*?, ","", (gsub("^.*?, ","", as.character(rawdata_within$by)))))))
rawdata_within$context <- as.factor(gsub("[(), ]", "", (gsub("\\d","", as.character(rawdata_within$by)))))
rawdata_within <- subset(rawdata_within, select = -c(by))
remove("acoustic", "betweenfile_cons", "betweenfile_vowels", "distance", "withinfile_cons", "withinfile_vowels")
par(pty="s")
plot(c(.45,1.), c(.45, 1.), type="n",xlab="Within-Speaker ABX Score",ylab="Across-Speaker ABX Score",main = "ABX scores", xlim=c(0.45,.99),ylim=c(0.45,.99), frame.plot = FALSE)
axis(side = 1)
for (thiscontrast in levels(rawdata_within$contrasts)) {
between_score = rawdata_between$score[rawdata_between$contrasts == thiscontrast]
within_score = rawdata_within$score[rawdata_within$contrasts == thiscontrast]
points(mean(within_score), mean(between_score), pch = 1, cex =1)
}
lines(c(0.45,1.),c(0.45,1.),col="red",lty=3)
levels(rawdata_within$contrasts)
within_score
between_score
hist(between_score)
hist(within_score)
within_score
length(within_score)
levels(rawdata_within$speaker)
length(levels(rawdata_within$speaker))
within$mean_score
between$mean_score
hist(between$mean_score)
hist(within$mean_score)
within = within_percontrastspeaker %>%
group_by(speakerpairs) %>%
summarise(mean_score = mean(mean_score_temp)) %>%
ungroup()
#Step 3: Final score
between_score = mean(between$mean_score)
within_score = mean(within$mean_score)
difference_score = within_score-between_score
sampling_data = merge(between, within, all = TRUE)
n_loops = 10000
n_within = length(within$speakerpairs)
n_between = length(between$speakerpairs)
within_results = matrix(NA, nrow = n_loops, ncol = 1)
between_results = matrix(NA, nrow = n_loops, ncol = 1)
diff_results = matrix(NA, nrow = n_loops, ncol = 1)
set.seed(111)
for(loop in 1:n_loops){
within_sampling_rows = sample(nrow(sampling_data), n_within)
sample_within = sampling_data[within_sampling_rows, ]
sample_between = sampling_data[-within_sampling_rows, ]
#Step 3: Final score, directly record
between_results[loop] = mean(sample_between$mean_score)
within_results[loop] = mean(sample_within$mean_score)
#→ do within minus between → (difference score)
diff_results[loop] = mean(sample_within$mean_score) - mean(sample_between$mean_score)
}
b<-barplot(diff_quants[1,], ylim=c(.0, .5), ylab = "ABX Difference Score", cex.names=1.2)
bd=.15 #  a hack to print the CIs as error bars
x=c(t(cbind(b,b,NaN)))
y=c(t(cbind(diff_quants[2, ],diff_quants[4,],NaN)))
x=c(t(cbind(b,b,b-bd,b+bd,NaN,b-bd,b+bd,NaN)))
y=c(t(cbind(diff_quants[2, ],diff_quants[4,],diff_quants[4,],diff_quants[4,],NaN,diff_quants[2, ],diff_quants[2, ],NaN)))
lines(x,y,col="#303030")
par(pty="s")
plot(c(.45,1.), c(.45, 1.), type="n",xlab="Within-Speaker ABX Score",ylab="Across-Speaker ABX Score",main = "ABX scores", xlim=c(0.45,.99),ylim=c(0.45,.99), frame.plot = FALSE)
axis(side = 1)
for (thiscontrast in levels(rawdata_within$contrasts)) {
between_score_plot = rawdata_between$score[rawdata_between$contrasts == thiscontrast]
within_score_plot = rawdata_within$score[rawdata_within$contrasts == thiscontrast]
points(mean(within_score_plot), mean(between_score_plot), pch = 1, cex =1)
}
lines(c(0.45,1.),c(0.45,1.),col="red",lty=3)
levels(rawdata_between$contrasts)
within
between
hist(between$mean_score)
hist(within$mean_score)
hist(rawdata_between$score)
hist(rawdata_within$score)
mean(rawdata_within$score)
mean(rawdata_between$score)
par(pty="s")
plot(c(.45,1.), c(.45, 1.), type="n",xlab="Within-Speaker ABX Score",ylab="Across-Speaker ABX Score",main = "ABX scores", xlim=c(0.45,.99),ylim=c(0.45,.99), frame.plot = FALSE)
axis(side = 1)
for (thiscontrast in levels(rawdata_within$contrasts)) {
between_score_plot = rawdata_between$score[rawdata_between$contrasts == thiscontrast]
within_score_plot = rawdata_within$score[rawdata_within$contrasts == thiscontrast]
points(mean(within_score_plot), mean(between_score_plot), pch = 1, cex =1)
}
lines(c(0.45,1.),c(0.45,1.),col="red",lty=3)
hist(diff_results)
vline(difference_score)
?vline
hist(diff_results, xlim =c(-.1, .1))
abline(v=difference_score, col = "red")
hist(diff_results, xlim =c(-.55, .55))
abline(v=difference_score, col = "red")
hist(diff_results, xlim =c(-.055, .055))
abline(v=difference_score, col = "red")
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE)
source("../Metalab/metalab/dashboard/global.R", chdir = TRUE) # Christina source
# source("../../Desktop/Experiments/MetaLab/metalab/dashboard/global.R", chdir = TRUE) # Page source
library(metafor)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(knitr)
library(broom)
library(pwr)
source('~/gitrepos/ABX-Brent/Scripts/DoInfStats.R', encoding = 'UTF-8', echo=TRUE)
source('~/gitrepos/ABX-Brent/Scripts/DoInfStats.R', encoding = 'UTF-8', echo=TRUE)
rawdata_within$speakerpairs = paste(rawdata_within$speaker, rawdata_within$speaker, sep="-")
between_percontrastspeaker = rawdata_between %>%
group_by(speakerpairs, contrasts) %>%
summarise(mean_score_temp = mean(score)) %>%
ungroup()
between_percontrastspeaker = rawdata_between %>%
group_by(speakerpairs, contrasts) %>%
summarise(mean_score_temp = mean(score)) %>%
ungroup()
within_percontrastspeaker = rawdata_within %>%
group_by(speakerpairs, contrasts) %>%
summarise(mean_score_temp = mean(score)) %>%
ungroup()
both=rbind(between_percontrastspeaker,within_percontrastspeaker)
both$sp_type=ifelse(substr(both$speakerpairs,1,2)==substr(both$speakerpairs,4,5),"w","b")
both$c_type<-"C"
both$c_type[grep("[aeiou]",both$contrasts)]<-"V"
both=data.frame(both)
whole=lm(mean_score_temp~contrasts+speakerpairs,data=both)
contrast_only=lm(mean_score_temp~contrasts,data=both)
speakers_only=lm(mean_score_temp~speakerpairs,data=both)
anova(whole,contrast_only)
anova(whole,speakers_only)
summary(contrast_only) #contrast ID explains 43% of the variance
summary(speakers_only) #speaker ID explains 4% of the variance  - 10x less !!
summary(whole) #the model with both explains 48% of the variance
write.table(both,"Supplementary/both_brent.txt",row.names=F,sep="\t")
